{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The cell below is for you to keep track of the libraries used and install those libraries quickly\n",
    "##### Ensure that the proper library names are used and the syntax of `%pip install PACKAGE_NAME` is followed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install pandas \n",
    "#%pip install matplotlib\n",
    "#%pip install numpy\n",
    "#%pip install matplotlib\n",
    "#%pip install xgboost\n",
    "# add commented pip installation lines for packages used as shown above for ease of testing\n",
    "# the line should be of the format %pip install PACKAGE_NAME "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DO NOT CHANGE** the filepath variable\n",
    "##### Instead, create a folder named 'data' in your current working directory and \n",
    "##### have the .csv file inside that. A relative path *must* be used when loading data into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can have as many cells as you want for code\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "filepath = \"./data/catA_train.csv\" \n",
    "df = pd.read_csv(filepath)\n",
    "# the initialised filepath MUST be a relative path to a folder named data that contains the parquet file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **ALL** Code for machine learning and dataset analysis should be entered below. \n",
    "##### Ensure that your code is clear and readable.\n",
    "##### Comments and Markdown notes are advised to direct attention to pieces of code you deem useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Exploring the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df[\"Entity Type\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 29182 entries in this dataset and 28 columns, with a mix of numerical and categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the number of missing values in the dataset \n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features with missing values are: \n",
    "1. Latitude and Longitude\n",
    "2. Year Found\n",
    "3. Parent Company and Parent Country \n",
    "4. Square Footage\n",
    "5. Employees (Single Site), Employees (Domestic Ultimate Total), Employees (Global Ultimate Total)\n",
    "6. Import/Export Status\n",
    "7. Fiscal Year End \n",
    "8. Global Ultimate Company and Global Ultimate Country \n",
    "9. Domestic Ultimate Company \n",
    "\n",
    "We will discuss how we handled these missing values in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Exploration and Visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_counts = df[\"Industry\"].value_counts()\n",
    "top_industries = industry_counts.head(5)\n",
    "other_count = industry_counts[5:].sum()\n",
    "top_industries['Other'] = other_count\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(top_industries, autopct='%1.1f%%', startangle=140,textprops={\"fontsize\" : 8})\n",
    "plt.title('Number of Companies by Industry (Top 5 Categories)')\n",
    "plt.legend(top_industries.index, title=\"Industries\", loc=\"lower left\", fontsize = 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe from the pie chart that the most common industry the companies are involved in are Offices of Holding Companies, we have also observed 582 unique industries in the dataset. As such, we will be trying to condense these categories further "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a scatter plot of \n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Sales (Global Ultimate Total USD)'], df['Sales (Domestic Ultimate Total USD)'])\n",
    "plt.title('Correlation between Global and Domestic Sales')\n",
    "plt.xlabel('Global Sales') \n",
    "plt.ylabel('Domestic Sales')  \n",
    "\n",
    "\n",
    "# Creating a scatter plot of lg domeestic sales vs lg globalsales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(np.log(df['Sales (Global Ultimate Total USD)']), np.log(df['Sales (Domestic Ultimate Total USD)']))\n",
    "plt.title('Correlation between log Global and log Domestic Sales')\n",
    "plt.xlabel('log Global Sales')  \n",
    "plt.ylabel('log Domestic Sales') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We explored the relationship between the Global Ultimate Sales and Domestic Ultimate Sales. In our initial plot, due to large scale of the numbers, we were unable to determine any relationship between the two features.\n",
    "\n",
    "We explored transforming the features and could observe that there was some correlation between the log-transformed variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scatterplot of global employee size and lg domestic sales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Employees (Global Ultimate Total)'], np.log(df['Sales (Domestic Ultimate Total USD)']))\n",
    "plt.title('Correlation between Employees(Global Ultimate Total) and Domestic Sales')\n",
    "plt.xlabel('Employees(Domestic )')  # x-axis label\n",
    "plt.ylabel('Domestic Sales')  # y-axis label\n",
    "\n",
    "#Scatterplot of domestic employee size and lg domestic sales\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df['Employees (Domestic Ultimate Total)'], np.log(df['Sales (Domestic Ultimate Total USD)']))\n",
    "plt.title('Correlation between Employees (Domestic Ultimate Total) and Domestic Sales')\n",
    "plt.xlabel('Employees(Global)')  # x-axis label\n",
    "plt.ylabel('Domestic Sales')  # y-axis label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there is some relationship between the size of the global and domestic ultiate workforce. We plan to investigate this relationship further in our modelling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_sales = df.groupby('Industry')['Sales (Domestic Ultimate Total USD)'].mean()\n",
    "top_industries = industry_sales.sort_values(ascending=False).head(5)\n",
    "plt.figure(figsize=(10, 6))  # Adjust the size as needed\n",
    "top_industries.plot(kind='barh')\n",
    "plt.title('Top 5 Industries by Average Sales')\n",
    "plt.xlabel('Average Total Sales')\n",
    "plt.ylabel('Industries')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the avergae sales by industries, we can observe that certain industries tend to have a significantly higher average sales than other industries, thus we are planning to explore the effect of industries on the domestic sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_sales = df.groupby('Global Ultimate Country')['Sales (Domestic Ultimate Total USD)'].mean()\n",
    "top_industries = industry_sales.sort_values(ascending=False).head(5)\n",
    "plt.figure(figsize=(10, 6))  # Adjust the size as needed\n",
    "top_industries.plot(kind='barh')\n",
    "plt.title('Top 5 Global Ultimate Countries by Average Sales')\n",
    "plt.ylabel('Global Ultimate Countries')\n",
    "plt.xlabel('Average Total Sales')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the avergae sales by Global Ultimate Countries, we can observe that certain Countries tend to have a significantly higher average sales than other countries, thus we are planning to explore the effect of countries on the domestic sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_sales = df.groupby('Parent Country')['Sales (Domestic Ultimate Total USD)'].mean()\n",
    "top_industries = industry_sales.sort_values(ascending=False).head(5)\n",
    "plt.figure(figsize=(10, 6))  # Adjust the size as needed\n",
    "top_industries.plot(kind='barh')\n",
    "plt.title('Top 5 Parent Countries by Average Sales')\n",
    "plt.ylabel('Parent Country')\n",
    "plt.xlabel('Average Total Sales')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysing the average sales by Parent Countries, we can observe that certain Countries tend to have a significantly higher average sales than other countries, thus we are planning to explore the effect of Parent countries on the domestic sales. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_sales = df.groupby('Import/Export Status')['Sales (Domestic Ultimate Total USD)'].mean()\n",
    "top_industries = industry_sales.sort_values(ascending=False).head(5)\n",
    "plt.figure(figsize=(10, 6))  # Adjust the size as needed\n",
    "top_industries.plot(kind='barh')\n",
    "plt.title('Top 5 Parent Countries by Average Sales')\n",
    "plt.ylabel('Import/Export Status')\n",
    "plt.xlabel('Average Total Sales')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the aveage sales for import/export type, we find that companies involved in both import and export, as well as those with missing values for this column share a relatiely higher average total domestic sales, we plan too further investigate this in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_counts = df[\"Industry\"].value_counts()\n",
    "top_industries = industry_counts.head(5)\n",
    "other_count = industry_counts[5:].sum()\n",
    "top_industries['Other'] = other_count\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(top_industries, autopct='%1.1f%%', startangle=140,textprops={\"fontsize\" : 8})\n",
    "plt.title('Number of Companies by Industry (Top 5 Categories)')\n",
    "plt.legend(top_industries.index, title=\"Industries\", loc=\"lower left\", fontsize = 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Handling of Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latitude and Longitude: we believe that the company location could be a significant feature in training the model, hence we decided to remove rows with missing values in these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with na values in longitude and latitude columns, as well as having negative sales\n",
    "df = df.dropna(subset=[\"LONGITUDE\", \"LATITUDE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Year Found: we decided to fill the missing values with mode since the other two possible imputers - median and mean seems to be rather high and we think that mode would be the more apporpriate imputer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Year Found\"] = df[\"Year Found\"].fillna(value = df[\"Year Found\"].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parent Country & Global Ultimate Country: We identified them to be potential important features. Therefore, for missing values in these two features, we classify the missing values as \"Missing\". However, we do not consider the exact company itself as that might lead to overfitting of the model, that includes Parent Company, Global Ultimate Company and Domestic Ultimate Company."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toReplace = [\"Parent Country\", \"Global Ultimate Country\"]\n",
    "df[toReplace] = df[toReplace].fillna(value = \"Missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fiscal Year End & Square Footage: these column have a lot of (or all) missing values and we think that this feature is not so meaningful, hence we decided to drop this feature entirely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Employees (Single Site, Domestic Ultimate Total, Global Ultimate Total): Since there are many missing values for Employee (Single Site), we decided to drop this feature entirely and utilized on Employees (Domestic Ultimate Total) as well as Employes (Global Ultimate Total). The missing values for the latter two are filled with the mean imputers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Employees (Domestic Ultimate Total)\"] = df[\"Employees (Domestic Ultimate Total)\"].fillna(df[\"Employees (Domestic Ultimate Total)\"].mean().round())\n",
    "df[\"Employees (Global Ultimate Total)\"] = df[\"Employees (Global Ultimate Total)\"].fillna(df[\"Employees (Global Ultimate Total)\"].mean().round())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import/Export Status: lastly, we believe this is important as this data sort of tells us the scale of the company. Therefore, we classify missing values as \"Missing\", same as what we did for Parent Country and Global Ultimate Country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Import/Export Status\"] = df[\"Import/Export Status\"].fillna(value = \"Missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, there are some negative sales data in the dataset and we decided to drop these rows. We also only consider active companies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df.index[df[\"Sales (Domestic Ultimate Total USD)\"] < 0])\n",
    "df = df.drop(df.index[df[\"Sales (Global Ultimate Total USD)\"] < 0])\n",
    "df = df.drop(df.index[df[\"Company Status (Active/Inactive)\"] == \"Inactive\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we think that it might be easier to work with the feature \"Age\" rather than \"Year Found\", since \"Age\" can be considered as a numerical variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Age\"] = pd.to_datetime(\"today\").year - df[\"Year Found\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many unique SIC codes in the dataset (582) which may lead to overfitting. Therefore, we found a relatively good guide online that helps us condense these SIC codes into 10 main industries. We will create a new column named \"Industry Type\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifySICcode(SIC):\n",
    "    if SIC//100 <= 9 and SIC//100 >= 1 : \n",
    "        return \"Agriculture, Forestry, Fishing\"\n",
    "    elif SIC//100 <= 14 and SIC//100 >= 10 : \n",
    "        return \"Mining\"\n",
    "    elif SIC//100 <= 17 and SIC//100 >= 15 : \n",
    "        return \"Construction\"\n",
    "    elif SIC//100 <= 39 and SIC//100 >= 20:\n",
    "        return \"Manufacturing\"\n",
    "    elif SIC//100 <= 49 and SIC//100 >= 40:\n",
    "        return \"Transportation & Public Utilities\"\n",
    "    elif SIC//100 <= 51 and SIC//100 >= 50:\n",
    "        return \"Wholesale Trade\"\n",
    "    elif SIC//100 <= 59 and SIC//100 >= 52:\n",
    "        return \"Retail Trade\"\n",
    "    elif SIC//100 <= 67 and SIC//100 >= 60:\n",
    "        return \"Finance, Insurance, Real Estate\"\n",
    "    elif SIC//100 <= 89 and SIC//100 >= 70:\n",
    "        return \"Services\"\n",
    "    elif SIC//100 <= 99 and SIC//100 >= 91 : \n",
    "        return \"Public Administration\"\n",
    "    else:\n",
    "        return \"Other\" \n",
    "    \n",
    "df[\"Industry Type\"] = df[\"SIC Code\"].transform(lambda x:classifySICcode(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "industry_counts = df[\"Industry Type\"].value_counts()\n",
    "top_industries = industry_counts.head(5)\n",
    "other_count = industry_counts[5:].sum()\n",
    "top_industries['Other'] = other_count\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.pie(top_industries, autopct='%1.1f%%', startangle=140,textprops={\"fontsize\" : 6})\n",
    "plt.title('Number of Companies by Industry Type')\n",
    "plt.legend(top_industries.index, title=\"Industries\", loc=\"lower left\", fontsize = 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By further categorising it into 10 smaller subgroups, we are able to gain a better understanding of the dataset and industries involved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the longitude and latitude data better, we try to group companies into different clusters using KMeans clustering and give them a label (a new column named \"Location Label\"). We choose the number of clusters to be 6 since Singapore has 6 large industrial parks spread across the Republic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# KMeans to cluster companies\n",
    "X = df[[\"LATITUDE\" , \"LONGITUDE\"]]\n",
    "kmeans = KMeans(n_clusters = 6, n_init=\"auto\").fit(X)\n",
    "df[\"Location Label\"] = kmeans.labels_\n",
    "\n",
    "# training KNN Clustering model to be used for new data \n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "labels = range(kmeans.n_clusters)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)  # Using 1 neighbor for exact match\n",
    "knn.fit(cluster_centers, labels)\n",
    "\n",
    "# Simple visualization of the cluster\n",
    "plt.scatter(df[\"LONGITUDE\"], df[\"LATITUDE\"], c = df[\"Location Label\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the features \"Parent Country\" and \"Global Ultimate Country\", if there are less than 10 occurences, we will classify them as \"Others\" instead to reduce the dimension of the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_parent = df[\"Parent Country\"].value_counts() \n",
    "low_freq_parent_countries = freq_parent[freq_parent < 10].index\n",
    "df[\"Parent Country\"] = df[\"Parent Country\"].replace(low_freq_parent_countries, \"Others\")\n",
    "\n",
    "# Do the same for Global Ultimate Country\n",
    "freq_global_ultimate = df[\"Global Ultimate Country\"].value_counts() \n",
    "low_freq_global_ultimate_countries = freq_global_ultimate[freq_global_ultimate < 10].index\n",
    "df[\"Global Ultimate Country\"] = df[\"Global Ultimate Country\"].replace(low_freq_global_ultimate_countries, \"Others\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We will also transform all categorical variables into indicator variables for model training purposes. We also drop irrelevant columns at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_to_keep = [\"Sales (Domestic Ultimate Total USD)\", \"Sales (Global Ultimate Total USD)\", \"Parent Country\", \n",
    "               \"Employees (Domestic Ultimate Total)\", \"Employees (Global Ultimate Total)\", \"Import/Export Status\", \n",
    "               \"Global Ultimate Country\", \"Is Domestic Ultimate\", \"Is Global Ultimate\", \"Age\", \"Location Label\", \n",
    "               \"Industry Type\", \"Ownership Type\"]\n",
    "df = df[col_to_keep]\n",
    "\n",
    "col_to_encode = [\"Parent Country\", \"Import/Export Status\", \"Global Ultimate Country\", \"Is Domestic Ultimate\", \n",
    "                 \"Is Global Ultimate\", \"Location Label\", \"Industry Type\", \"Ownership Type\"]\n",
    "for var in col_to_encode:\n",
    "    encoded = pd.get_dummies(df[var], prefix = var)\n",
    "    df = df.drop(var, axis = 1)\n",
    "    df = pd.concat([df, encoded], axis = 1)\n",
    "\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to use one of the most robust and accurate algorithm (XGBoost) to build our predictive model. For evaluation metrics, we will be using R^2 values. We will also be conducting cross validation using the k-fold method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# We first separate our features and target variable\n",
    "X = df.drop([\"Sales (Domestic Ultimate Total USD)\"], axis = 1)\n",
    "y = df[\"Sales (Domestic Ultimate Total USD)\"]\n",
    "\n",
    "# Initialize model \n",
    "model = XGBRegressor(n_estimators = 239, max_depth = 5, learning_rate = 0.18)\n",
    "\n",
    "for i in range(3):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "    # Use 20-fold \n",
    "    kf = KFold(n_splits = 20, shuffle = True)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv = kf, scoring = \"r2\")\n",
    "\n",
    "    print(\"CV R^2 errors: \", cv_scores)\n",
    "    print(\"Mean R^2 errors: \", cv_scores.mean())\n",
    "\n",
    "    # Train and evaluate \n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    print(\"R-squared error on test set: \", r2_score(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see from the performance above, generally, the model performs quite well in terms of r-squared value. The final hyperparameters chosen for the XGBoostRegressor is based on multiple trials and errors with some help on the library Optuna. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "feature_importance = model.feature_importances_\n",
    "index = feature_importance.argsort()[::-1]\n",
    "\n",
    "# Simple Visualization\n",
    "plot_importance(model, max_num_features = 10, importance_type = \"cover\")\n",
    "plot_importance(model, max_num_features = 10, importance_type = \"weight\")\n",
    "plot_importance(model, max_num_features = 10, importance_type = \"gain\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 Methods of Computing Feature Importance:\n",
    "- Weight: The number of times a feature appears in a tree across the ensemble of trees.\n",
    "- Gain: The average gain of a feature when it is used in trees.\n",
    "- Cover: The average coverage of a feature when it is used in trees.\n",
    "\n",
    "\n",
    "Based on the chart for the weight of feature importance, it seems that most of features that we exlpored in our data analysis have also shown up on the chart. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we fit all data in the dataset using the final parameters we have and save the final model as BestModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import joblib\n",
    "\n",
    "# We first separate our features and target variable\n",
    "X = df.drop([\"Sales (Domestic Ultimate Total USD)\"], axis = 1)\n",
    "y = df[\"Sales (Domestic Ultimate Total USD)\"]\n",
    "\n",
    "# Initialize model \n",
    "BestModel = XGBRegressor(n_estimators = 239, max_depth = 5, learning_rate = 0.18)\n",
    "BestModel.fit(X, y)\n",
    "joblib.dump(BestModel, \"FinalModel.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The cell below is **NOT** to be removed\n",
    "##### The function is to be amended so that it accepts the given input (dataframe) and returns the required output (list). \n",
    "##### It is recommended to test the function out prior to submission\n",
    "-------------------------------------------------------------------------------------------------------------------------------\n",
    "##### The hidden_data parsed into the function below will have the same layout columns wise as the dataset *SENT* to you\n",
    "##### Thus, ensure that steps taken to modify the initial dataset to fit into the model are also carried out in the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_hidden_data(hidden_data: pd.DataFrame) -> list:\n",
    "    '''DO NOT REMOVE THIS FUNCTION.\n",
    "\n",
    "The function accepts a dataframe as input and return an iterable (list)\n",
    "of binary classes as output.\n",
    "\n",
    "The function should be coded to test on hidden data\n",
    "and should include any preprocessing functions needed for your model to perform. \n",
    "    \n",
    "All relevant code MUST be included in this function.'''\n",
    "\n",
    "    df = hidden_data\n",
    "    # fill missing values of longitude and latitude with mean \n",
    "    df[\"LATITUDE\"] = df[\"LATITUDE\"].fillna(value = df[\"LATITUDE\"].mean())\n",
    "    df[\"LONGITUDE\"] = df[\"LONGITUDE\"].fillna(value = df[\"LONGITUDE\"].mean())\n",
    "    df[\"Location Label\"] = knn.predict(df[[\"LATITUDE\", \"LONGITUDE\"]])\n",
    "\n",
    "    # fill missing values of years with mode \n",
    "    df[\"Year Found\"] = df[\"Year Found\"].fillna(value = df[\"Year Found\"].mode()[0])\n",
    "    df[\"Age\"] = pd.to_datetime(\"today\").year - df[\"Year Found\"]\n",
    "\n",
    "    # fill missing values of global sales with mode \n",
    "    df[\"Sales (Global Ultimate Total USD)\"] = df[\"Sales (Global Ultimate Total USD)\"].fillna(value = df[\"Sales (Global Ultimate Total USD)\"].mean())\n",
    "\n",
    "    # Convert SIC code to industry type \n",
    "    def classifySICcode(SIC):\n",
    "        if SIC//100 <= 9 and SIC//100 >= 1 : \n",
    "            return \"Agriculture, Forestry, Fishing\"\n",
    "        elif SIC//100 <= 14 and SIC//100 >= 10 : \n",
    "            return \"Mining\"\n",
    "        elif SIC//100 <= 17 and SIC//100 >= 15 : \n",
    "            return \"Construction\"\n",
    "        elif SIC//100 <= 39 and SIC//100 >= 20:\n",
    "            return \"Manufacturing\"\n",
    "        elif SIC//100 <= 49 and SIC//100 >= 40:\n",
    "            return \"Transportation & Public Utilities\"\n",
    "        elif SIC//100 <= 51 and SIC//100 >= 50:\n",
    "            return \"Wholesale Trade\"\n",
    "        elif SIC//100 <= 59 and SIC//100 >= 52:\n",
    "            return \"Retail Trade\"\n",
    "        elif SIC//100 <= 67 and SIC//100 >= 60:\n",
    "            return \"Finance, Insurance, Real Estate\"\n",
    "        elif SIC//100 <= 89 and SIC//100 >= 70:\n",
    "            return \"Services\"\n",
    "        elif SIC//100 <= 99 and SIC//100 >= 91 : \n",
    "            return \"Public Administration\"\n",
    "        else:\n",
    "            return \"Other\" \n",
    "    \n",
    "    df[\"SIC Code\"] = df[\"SIC Code\"].fillna(df[\"SIC Code\"].mode()[0])\n",
    "    df[\"Industry Type\"] = df[\"SIC Code\"].transform(lambda x:classifySICcode(x))\n",
    "\n",
    "    # Fill missing values for employees\n",
    "    df[\"Employees (Domestic Ultimate Total)\"] = df[\"Employees (Domestic Ultimate Total)\"].fillna(df[\"Employees (Domestic Ultimate Total)\"].mean().round())\n",
    "    df[\"Employees (Global Ultimate Total)\"] = df[\"Employees (Global Ultimate Total)\"].fillna(df[\"Employees (Global Ultimate Total)\"].mean().round())\n",
    "\n",
    "    # Fill NA Import/Export Status with \"Missing\"\n",
    "    df[\"Import/Export Status\"] = df[\"Import/Export Status\"].fillna(value = \"Missing\")\n",
    "\n",
    "    # Replace missing Country with \"Missing\"\n",
    "    toReplace = [\"Parent Country\", \"Global Ultimate Country\"]\n",
    "    df[toReplace] = df[toReplace].fillna(value = \"Missing\")\n",
    "\n",
    "    # Classify new countries as Others\n",
    "    GlobalCountries = ['United Kingdom', 'Singapore', 'Hong Kong SAR', 'France', 'Germany',\n",
    " 'Cayman Islands' ,'Switzerland', 'Norway', 'Spain', 'Denmark', 'India',\n",
    " 'Curacao' ,'Missing' ,'United States', 'Japan', 'China', 'Luxembourg',\n",
    " 'Virgin Islands (British)', 'Panama', 'Netherlands' ,'Italy', 'Malaysia',\n",
    " 'Australia' ,'Korea, Republic of' ,'Canada', 'Taiwan' ,'Others' ,'Vietnam',\n",
    " 'Indonesia', 'Sweden', 'United Arab Emirates', 'Portugal' ,'New Zealand',\n",
    " 'Ireland' ,'Finland' ,'Thailand' ,'Austria', 'Belgium' ,'Bermuda',\n",
    " 'South Africa' ,'Brazil' ,'Mauritius' ,'Israel', 'Cyprus', 'Philippines',\n",
    " 'Liechtenstein']\n",
    "    \n",
    "    ParentCountries = ['Singapore' ,'Hong Kong SAR', 'Netherlands', 'Cayman Islands' ,'Luxembourg',\n",
    " 'Switzerland' ,'Spain' ,'Denmark' ,'India', 'Missing' ,'United Kingdom',\n",
    " 'Japan' ,'United States' ,'China' ,'Germany', 'Virgin Islands (British)',\n",
    " 'Malaysia', 'Korea, Republic of', 'France', 'Australia', 'Taiwan', 'Norway',\n",
    " 'Others' ,'Bermuda', 'Ireland' ,'Canada' ,'Vietnam', 'Indonesia', 'Sweden',\n",
    " 'United Arab Emirates' ,'Cyprus', 'New Zealand' ,'Thailand' ,'Austria',\n",
    " 'Israel' ,'Belgium' ,'Italy', 'Philippines', 'Malta' ,'Finland', 'Mauritius',\n",
    " 'Panama']\n",
    "    \n",
    "    df[\"Parent Country\"] = df[\"Parent Country\"].where(df[\"Parent Country\"].isin(ParentCountries), \"Others\")\n",
    "    df[\"Global Ultimate Country\"] = df[\"Global Ultimate Country\"].where(df[\"Global Ultimate Country\"].isin(GlobalCountries), \"Others\")\n",
    "    \n",
    "    # fill missing values of ownership type with mode\n",
    "    df[\"Ownership Type\"] = df[\"Ownership Type\"].fillna(value = df[\"Ownership Type\"].mode()[0])\n",
    "\n",
    "    # fill is domestic/global ultimate with mode \n",
    "    df[\"Is Domestic Ultimate\"] = df[\"Is Domestic Ultimate\"].fillna(value = df[\"Is Domestic Ultimate\"].mode()[0])\n",
    "    df[\"Is Global Ultimate\"] = df[\"Is Global Ultimate\"].fillna(value = df[\"Is Global Ultimate\"].mode()[0])\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    col_to_keep = [\"Sales (Global Ultimate Total USD)\", \"Parent Country\", \n",
    "               \"Employees (Domestic Ultimate Total)\", \"Employees (Global Ultimate Total)\", \"Import/Export Status\", \n",
    "               \"Global Ultimate Country\", \"Is Domestic Ultimate\", \"Is Global Ultimate\", \"Age\", \"Location Label\", \n",
    "               \"Industry Type\", \"Ownership Type\"]\n",
    "    df = df[col_to_keep]\n",
    "\n",
    "    col_to_encode = [\"Parent Country\", \"Import/Export Status\", \"Global Ultimate Country\", \"Is Domestic Ultimate\", \n",
    "                 \"Is Global Ultimate\", \"Location Label\", \"Industry Type\", \"Ownership Type\"]\n",
    "    \n",
    "    \n",
    "    for var in col_to_encode:\n",
    "        encoded = pd.get_dummies(df[var], prefix = var)\n",
    "        df = df.drop(var, axis = 1)\n",
    "        df = pd.concat([df, encoded], axis = 1)\n",
    "\n",
    "    loaded_model = joblib.load('./FinalModel.h5')\n",
    "    result = loaded_model.predict(df)\n",
    "    \n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cell to check testing_hidden_data function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell should output a list of predictions.\n",
    "filepath = \"./data/catA_train.csv\" \n",
    "test_df = pd.read_csv(filepath)\n",
    "y = test_df['Sales (Domestic Ultimate Total USD)']\n",
    "test_df = test_df.drop(columns=['Sales (Domestic Ultimate Total USD)'])\n",
    "print(testing_hidden_data(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please have the filename renamed and ensure that it can be run with the requirements above being met. All the best!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
